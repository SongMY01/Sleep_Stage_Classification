1. 결정 트리(Decision Tree)
데이터 분류, 회귀 분석 수행 모델
학습 : 데이터의 모든 특징으로 분할. 재귀적 분할
장점 : 직관적이고 시각화 쉬움. 복잡한 비선형 관계 효과적 처리.
단점 : 과적합되기 쉬움. 데이터가 조금만 변해도 트리 구조가 크게 바뀜(불안정성)

2. 서포트 벡터 머신(Support Vector Machine, SVM)
고차원 공간에서 최적의 초평면을 찾아 분류하는 모델
학습 : 최적화 문제 해결 방식
장점 : 고차원 데이터에 효과적. 비선형 데이터 효과적 분류. 과적합 방지 가능.
단점 : 대규모 데이터셋에서 학습 속도와 메모리 사용 비효율적. 많은 실험 필요. 결과가 직관적이지 않음(해석 필요)

3. K-Nearest Neighbors(KNN)
학습 : 학습 과정이 없는 비모수 모델. 데이터 저장 후 거리 계산 수행.
장점 : 직관적이고 간단하게 구현. 학습과정이 없기 때문에 훈련 시간 필요 없음. 분류, 회귀 문제 모두에 적용 가능.
단점 : 모든 데이터의 거리 계산 필요(데이터가 클 경우 느림). 특징 값을 정규화 하여 거리를 계산해야 함. K에 따라 성능 차이가 심함.
